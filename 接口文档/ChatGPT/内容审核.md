

# OpenAI/审查（Moderations）

## POST 创建内容审核

POST /v1/moderations

对文本是否违反 OpenAI 的内容政策进行分类

> Body 请求参数

```json
{
  "input": "I want to kill them."
}
```

### 请求参数

|名称|位置|类型|必选|说明|
|---|---|---|---|---|
|Authorization|header|string| 否 |none|
|body|body|object| 否 |none|
|» input|body|string| 是 |要分类的输入文本|
|» model|body|string| 是 |有两种内容审核模型可用：`text-moderation-stable`和`text-moderation-latest`。  默认值`text-moderation-latest`将随着时间的推移自动升级。这可确保您始终使用我们最准确的模型。如果您使用`text-moderation-stable`，我们将在更新模型之前提供提前通知。的准确度`text-moderation-stable`可能略低于 的准确度`text-moderation-latest`。|

> 返回示例

> Create moderation

```json
{
  "id": "modr-5MWoLO",
  "model": "text-moderation-001",
  "results": [
    {
      "categories": {
        "hate": false,
        "hate/threatening": true,
        "self-harm": false,
        "sexual": false,
        "sexual/minors": false,
        "violence": true,
        "violence/graphic": false
      },
      "category_scores": {
        "hate": 0.22714105248451233,
        "hate/threatening": 0.4132447838783264,
        "self-harm": 0.005232391878962517,
        "sexual": 0.01407341007143259,
        "sexual/minors": 0.0038522258400917053,
        "violence": 0.9223177433013916,
        "violence/graphic": 0.036865197122097015
      },
      "flagged": true
    }
  ]
}
```

### 返回结果

|状态码|状态码含义|说明|数据模型|
|---|---|---|---|
|200|[OK](https://tools.ietf.org/html/rfc7231#section-6.3.1)|Create moderation|Inline|

### 返回数据结构

状态码 **200**

|名称|类型|必选|约束|中文名|说明|
|---|---|---|---|---|---|
|» id|string|true|none||审核任务的唯一标识符|
|» model|string|true|none||用于审核的模型|
|» results|[object]|true|none||审核结果的详细信息|
|»» categories|object|false|none||审核模型检测到的所有分类标签|
|»»» hate|boolean|true|none||审核模型检测到是否存在仇恨言论|
|»»» hate|boolean|true|none||none|
|»»» self-harm|boolean|true|none||审核模型检测到是否存在自残内容|
|»»» sexual|boolean|true|none||审核模型检测到是否存在性内容|
|»»» sexual|boolean|true|none||none|
|»»» violence|boolean|true|none||审核模型检测到是否存在暴力内容|
|»»» violence|boolean|true|none||none|
|»» category_scores|object|false|none||审核模型对所有分类标签的得分|
|»»» hate|number|true|none||审核模型对仇恨言论的得分|
|»»» hate|number|true|none||none|
|»»» self-harm|number|true|none||审核模型对自残内容的得分|
|»»» sexual|number|true|none||审核模型对性内容的得分|
|»»» sexual|number|true|none||none|
|»»» violence|number|true|none||审核模型对暴力内容的得分|
|»»» violence|number|true|none||none|
|»» flagged|boolean|false|none||审核模型是否将输入内容标记为可疑内容|
